{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GPU perftest 2D\n",
    "\n",
    "Load modules"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using CUDA\n",
    "using BenchmarkTools"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "FD derivatives macros"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "macro d2_xi(A) esc(:(($A[ix+2, iy+1] - $A[ix+1, iy+1]) - ($A[ix+1, iy+1] - $A[ix, iy+1]))) end\n",
    "macro d2_yi(A) esc(:(($A[ix+1, iy+2] - $A[ix+1, iy+1]) - ($A[ix+1, iy+1] - $A[ix+1, iy]))) end\n",
    "macro all(A)  esc(:($A[ix, iy])) end\n",
    "macro inn(A)  esc(:($A[ix+1, iy+1])) end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Memory copy \"saxpy\" function"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function memcopy!(C2, C, D, dt)\n",
    "    ix = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y - 1) * blockDim().y + threadIdx().y\n",
    "    if (ix <= size(C, 1) && iy <= size(C, 2))\n",
    "        @inbounds @all(C2) = @all(C) + dt * @all(D)\n",
    "    end\n",
    "    return\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Laplacian or diffusion step function"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function diffusion_step!(C2, C, D, dt, _dx, _dy)\n",
    "    ix = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y - 1) * blockDim().y + threadIdx().y\n",
    "    if (ix <= size(C, 1) - 2 && iy <= size(C, 2) - 2)\n",
    "        @inbounds @inn(C2) = @inn(C) + dt * @inn(D) * (@d2_xi(C) * _dx * _dx + @d2_yi(C) * _dy * _dy)\n",
    "    end\n",
    "    return\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performance test \"lab\""
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function perftest()\n",
    "    nx = ny = 512 * 32 # 512 * 64\n",
    "    C  = CUDA.rand(Float64, nx, ny)\n",
    "    D  = CUDA.rand(Float64, nx, ny)\n",
    "    _dx = _dy = dt = rand()\n",
    "    C2 = copy(C)\n",
    "    nthreads = (16, 16)\n",
    "    nblocks  = cld.((nx, ny), nthreads)\n",
    "    # memory copy\n",
    "    t_it_mcpy = @belapsed begin\n",
    "        CUDA.@sync @cuda threads=$nthreads blocks=$nblocks memcopy!($C2, $C, $D, $dt)\n",
    "    end\n",
    "    T_peak = (2 * 1 + 1) / 1e9 * nx * ny * sizeof(Float64) / t_it_mcpy\n",
    "    # Laplacian\n",
    "    t_it = @belapsed begin\n",
    "        CUDA.@sync @cuda threads=$nthreads blocks=$nblocks diffusion_step!($C2, $C, $D, $dt, $_dx, $_dy)\n",
    "    end\n",
    "    T_eff = (2 * 1 + 1) / 1e9 * nx * ny * sizeof(Float64) / t_it\n",
    "    println(\"T_eff = $(round(T_eff, sigdigits=6)) GiB/s (T_peak = $(round(T_peak, sigdigits=6)) GiB/s) using CUDA.jl on an Nvidia GPU\")\n",
    "    println(\"So that's cool. We are running at $(round(T_eff/T_peak*100, sigdigits=4)) % of memory copy (T_peak)! ðŸš€\")\n",
    "    return\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the perf test"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "perftest()"
   ],
   "metadata": {},
   "execution_count": null
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  },
  "kernelspec": {
   "name": "julia-1.10",
   "display_name": "Julia 1.10.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
